# -*- coding: utf-8 -*-
"""Drowsiness Detection.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Vid_Fbtcb3-LI7dDO-wFL1JLo0RhSl3u
"""

import zipfile
import os


zip_path = '/content/DatasetF.zip'

# Define the directory to extract to
extract_path = '/content/Dataset/'

# Create the extraction directory if it doesn't exist
if not os.path.exists(extract_path):
    os.makedirs(extract_path)

# Unzip the file
with zipfile.ZipFile(zip_path, 'r') as zip_ref:
    zip_ref.extractall(extract_path)

print("Unzipping complete.")

import tensorflow as tf
import cv2
import os
import matplotlib.pyplot as plt
import numpy as np

img_array = cv2.imread("/content/Dataset/Dataset/Closed_Eyes/s0001_00001_0_0_0_0_0_01.png", cv2.IMREAD_GRAYSCALE)

plt.imshow(img_array, cmap="gray")

Datadirectory = "/content/Dataset/Dataset"
Classes = ["Closed_Eyes","Open_Eyes"]
for category in Classes:
  path = os.path.join(Datadirectory,category)
  for img in os.listdir(path):
    img_array = cv2.imread(os.path.join(path,img), cv2.IMREAD_GRAYSCALE)
    backtorbg = cv2.cvtColor(img_array,cv2.COLOR_GRAY2RGB)
    plt.imshow(img_array, cmap="gray")
    plt.show()
    break
  break

img_size = 224

new_array = cv2.resize(backtorbg, (img_size, img_size))
plt.imshow(new_array, cmap = "gray")
plt.show()

training_Data = []

def create_training_Data():
    for category in Classes:
        path = os.path.join(Datadirectory, category)
        class_num = Classes.index(category)
        print(f"Processing category: {category}, Path: {path}")

        for img in os.listdir(path):
            try:
                img_path = os.path.join(path, img)
                img_array = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)

                if img_array is None:
                    print(f"Failed to read image: {img_path}")
                    continue

                backtorbg = cv2.cvtColor(img_array, cv2.COLOR_GRAY2RGB)
                new_array = cv2.resize(backtorbg, (img_size, img_size))
                training_Data.append([new_array, class_num])
                print(f"Processed image: {img_path}")

            except Exception as e:
                print(f"Error processing image {img_path}: {e}")
                continue

create_training_Data()
print(f"Number of training samples: {len(training_Data)}")

print(len(training_Data))

reduced_size = 2000

import random

random.shuffle(training_Data)
reduced_size = 2000
training_Data = training_Data[:reduced_size]

len(training_Data)

X = []
y = []

for features, label in training_Data:
  X.append(features)
  y.append(label)

X = np.array(X).reshape(-1, img_size, img_size, 3)
Y = np.array(y)

X.shape

Y.shape

#normalize the data
from sklearn.preprocessing import StandardScaler
X_flattened = X.reshape(X.shape[0], -1)

# Normalize the data using StandardScaler
scaler = StandardScaler()
X_flattened_scaled = scaler.fit_transform(X_flattened)

# Reshape back to original shape
X = X_flattened_scaled.reshape(X.shape)

print(f"Scaled X shape: {X.shape}")

Y = np.array(y)

import pickle

pickle_out = open("X.pickle", "wb")
pickle.dump(X, pickle_out)
pickle_out.close()

pickle_out = open("Y.pickle", "wb")
pickle.dump(Y, pickle_out)
pickle_out.close()

"""Deep Learning Model

"""

Y.shape

import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers

model = tf.keras.applications.mobilenet.MobileNet()

model.summary()

"""Transfer Learning"""

base_input = model.layers[0].input

base_output = model.layers[-4].output

flat_layer = layers.Flatten()(base_output)
final_output = layers.Dense(1)(flat_layer)
final_output = layers.Activation('sigmoid')(final_output)

new_model = keras.Model(inputs = base_input, outputs= final_output)

new_model.summary()

new_model.compile(loss = "binary_crossentropy", optimizer = "adam", metrics = ["accuracy"])

history = new_model.fit(X, Y, epochs = 5, validation_split = 0.1)

print(f"Original X shape: {X.shape}")
print(f"Original Y shape: {Y.shape}")

new_model.save('my_model.h5')

new_model = tf.keras.models.load_model('my_model.h5')

img_array = cv2.imread('/content/WhatsApp Image 2024-07-07 at 12.17.18_058945cc.png', cv2.IMREAD_GRAYSCALE)
backtorgb = cv2.cvtColor(img_array, cv2.COLOR_GRAY2RGB)
new_array = cv2.resize(backtorgb,(img_size, img_size))

X_input = np.array(new_array).reshape(1, img_size, img_size, 3)

X_input.shape

plt.imshow(new_array)

X_input = X_input/255.0

prediction = new_model.predict(X_input)

threshold = 0.5

# Apply thresholding to get the class label
if prediction <= threshold:
    predicted_class = "closed eye"
else:
    predicted_class = "open eye"

print(f"Prediction Score: {prediction}")
print(f"Predicted Class: {predicted_class}")

import numpy as np
import os
import cv2
import tensorflow as tf
from tensorflow.keras import layers, models
from sklearn.preprocessing import StandardScaler
from sklearn.utils import shuffle
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report
import matplotlib.pyplot as plt
import seaborn as sns
import random
import pickle

predictions = (new_model.predict(X) > 0.5).astype("int32")
print("Accuracy:", accuracy_score(y, predictions))
print("Precision:", precision_score(y, predictions))
print("Recall:", recall_score(y, predictions))
print("F1-Score:", f1_score(y, predictions))
print("Confusion Matrix:\n", confusion_matrix(y, predictions))
print("Classification Report:\n", classification_report(y, predictions))

plt.figure(figsize=(12, 4))
plt.subplot(1, 2, 1)
plt.plot(history.history['accuracy'])
plt.plot(history.history['val_accuracy'])
plt.title('Model accuracy')
plt.ylabel('Accuracy')
plt.xlabel('Epoch')
plt.legend(['Train', 'Validation'], loc='upper left')

plt.subplot(1, 2, 2)
plt.plot(history.history['loss'])
plt.plot(history.history['val_loss'])
plt.title('Model loss')
plt.ylabel('Loss')
plt.xlabel('Epoch')
plt.legend(['Train', 'Validation'], loc='upper left')

plt.tight_layout()
plt.show()

conf_matrix = confusion_matrix(y, predictions)
plt.figure(figsize=(8, 6))
sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues')
plt.title('Confusion Matrix')
plt.xlabel('Predicted Label')
plt.ylabel('True Label')
plt.show()